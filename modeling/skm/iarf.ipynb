{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultiflow.meta import AdaptiveRandomForestClassifier as ARF\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import classification_report\n",
    "from skmultiflow.drift_detection import ADWIN\n",
    "from skmultiflow.data.file_stream import FileStream\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.insert(0, \"D:\\Datasets\")\n",
    "from config import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultiflow.utils import get_dimensions, check_weights\n",
    "\n",
    "class IARF(ARF):\n",
    "    def __init__(self, n=10, m='auto', a=0.01, b=0.001):\n",
    "        '''\n",
    "        - m: maximum features for per split\n",
    "        - n: number of base trees\n",
    "        - a: warning threshold\n",
    "        - b: drift threshold\n",
    "        '''\n",
    "\n",
    "        self.max_features = m\n",
    "        self.warning_detector = ADWIN(a)\n",
    "        self.drift_detector = ADWIN(b)\n",
    "        self.n_models = n\n",
    "        super().__init__(n_estimators=self.n_models, max_features=self.max_features, \n",
    "                       warning_detection_method=self.warning_detector,\n",
    "                       drift_detection_method=self.drift_detector)\n",
    "\n",
    "\n",
    "    def partial_fit(self, X, y, classes=None, sample_weight=None):\n",
    "        \"\"\" Partially (incrementally) fit the model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy.ndarray of shape (n_samples, n_features)\n",
    "            The features to train the model.\n",
    "\n",
    "        y: numpy.ndarray of shape (n_samples)\n",
    "            An array-like with the class labels of all samples in X.\n",
    "\n",
    "        classes: numpy.ndarray, list, optional (default=None)\n",
    "            Array with all possible/known class labels. This is an optional parameter, except\n",
    "            for the first partial_fit call where it is compulsory.\n",
    "\n",
    "        sample_weight: numpy.ndarray of shape (n_samples), optional (default=None)\n",
    "            Samples weight. If not provided, uniform weights are assumed.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self\n",
    "\n",
    "        \"\"\"\n",
    "        if self.classes is None and classes is not None:\n",
    "            self.classes = classes\n",
    "\n",
    "        if sample_weight is None:\n",
    "            weight = 1.0\n",
    "        else:\n",
    "            weight = sample_weight\n",
    "\n",
    "        if y is not None:\n",
    "            row_cnt, _ = get_dimensions(X)\n",
    "            weight = check_weights(weight, expand_length=row_cnt)\n",
    "            for i in range(row_cnt):\n",
    "                if self.predict([X[i]]) == y[i]:\n",
    "                    continue\n",
    "                if weight[i] != 0.0:\n",
    "                    self._train_weight_seen_by_model += weight[i]\n",
    "                    self._partial_fit(X[i], y[i], self.classes, weight[i])\n",
    "\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../csv/signle_data/merged_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2023)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IARF(a=None, b=None, m=None, n=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iarf = IARF()\n",
    "iarf.partial_fit(X_train, y_train, classes=np.unique(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = iarf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.95      0.98      0.96      2021\n",
      "      Dridex       1.00      1.00      1.00      1933\n",
      "    Trickbot       0.99      0.99      0.99      1943\n",
      "     Vawtrak       0.99      0.99      0.99      1659\n",
      "      Tiuref       0.99      0.98      0.98      1045\n",
      "        Zeus       0.91      0.97      0.94       388\n",
      "    Tancitor       0.94      0.87      0.91       684\n",
      "  Zeus-panda       0.96      0.79      0.87       120\n",
      "    Treambot       1.00      1.00      1.00        82\n",
      "     Gootkit       1.00      0.95      0.97        61\n",
      "\n",
      "    accuracy                           0.98      9936\n",
      "   macro avg       0.97      0.95      0.96      9936\n",
      "weighted avg       0.98      0.98      0.98      9936\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = [inverse_labels[label] for label in sorted(set(y_test))]\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
